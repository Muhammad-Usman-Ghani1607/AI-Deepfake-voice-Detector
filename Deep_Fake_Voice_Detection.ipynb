{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6358196,"sourceType":"datasetVersion","datasetId":3579787}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport librosa\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch import nn, optim, utils\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport torch.nn.functional as F\n\n# ------------------------------------------------------------------------------\n# 1️⃣ Enhanced Audio Loading, Normalization, and Augmentation\ndef extract_features(filename, n_mels=40, sr=16000, max_length=500, augment=False):\n    audio, sr = librosa.load(filename, sr=sr)\n    audio = librosa.util.normalize(audio)\n\n    if augment:\n        # Time-stretch with more aggressive range\n        rate = np.random.uniform(0.8, 1.2)\n        audio = librosa.effects.time_stretch(y=audio, rate=rate)\n\n        # Pitch shift with wider range\n        n_steps = np.random.randint(-3, 4)  # -3 to +3 semitones\n        audio = librosa.effects.pitch_shift(y=audio, sr=sr, n_steps=n_steps)\n        \n        # Add random noise\n        noise_amp = 0.005 * np.random.uniform() * np.amax(audio)\n        audio = audio + noise_amp * np.random.normal(size=audio.shape[0])\n        \n        # Random gain\n        gain = np.random.uniform(0.8, 1.2)\n        audio = audio * gain\n        \n        # Randomly drop some frequencies (spectral masking)\n        if np.random.rand() < 0.3:\n            n_fft = 2048\n            S = librosa.stft(audio, n_fft=n_fft)\n            mask = np.random.rand(*S.shape) > 0.2  # 20% chance to mask\n            S = S * mask\n            audio = librosa.istft(S)\n\n    mel = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels)\n    mel_db = librosa.power_to_db(mel, ref=np.max)\n\n    if mel_db.shape[1] < max_length:\n        pad = max_length - mel_db.shape[1]\n        mel_db = np.pad(mel_db, ((0, 0), (0, pad)), mode='constant')\n    else:\n        mel_db = mel_db[:, :max_length]\n\n    return mel_db\n\n# ------------------------------------------------------------------------------\n# 2️⃣ Prepare the data with more aggressive augmentation\nX, y = [], []\n\nfor label, directory in [(0, \"/kaggle/input/deep-voice-deepfake-voice-recognition/KAGGLE/AUDIO/REAL\"),\n                         (1, \"/kaggle/input/deep-voice-deepfake-voice-recognition/KAGGLE/AUDIO/FAKE\")]:\n    for file in os.listdir(directory):\n        file_path = os.path.join(directory, file)\n        \n        # Always extract original features\n        mel = extract_features(file_path, augment=False)\n        X.append(mel)\n        y.append(label)\n        \n        # Add augmented versions (3 per sample)\n        for _ in range(3):\n            mel_aug = extract_features(file_path, augment=True)\n            X.append(mel_aug)\n            y.append(label)\n\nX = np.array(X, dtype='float32')\ny = np.array(y, dtype='float32')\n\n# ------------------------------------------------------------------------------\n# 3️⃣ Prepare for training\nX = np.expand_dims(X, 1)  # (samples, 1, 40, max_length)\n\nX_tensor = torch.tensor(X, dtype=torch.float32)\ny_tensor = torch.tensor(y, dtype=torch.long)\n\nX_train, X_val, y_train, y_val = train_test_split(X_tensor, y_tensor, \n                                                  test_size=0.2, \n                                                  random_state=42,\n                                                  stratify=y)\n\ntrain_ds = utils.data.TensorDataset(X_train, y_train)\nval_ds = utils.data.TensorDataset(X_val, y_val)\n\ntrain_loader = utils.data.DataLoader(train_ds, batch_size=32, shuffle=True)\nval_loader = utils.data.DataLoader(val_ds, batch_size=32, shuffle=False)\n\n# ------------------------------------------------------------------------------\n# 4️⃣ Improved CNN architecture with regularization\nclass CNN(nn.Module):\n    def __init__(self, n_classes=2):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(16),\n            nn.LeakyReLU(negative_slope=0.1),\n            nn.MaxPool2d(2, 2),\n            nn.Dropout2d(0.25)\n        )\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.LeakyReLU(negative_slope=0.1),\n            nn.MaxPool2d(2, 2),\n            nn.Dropout2d(0.25)\n        )\n        self.conv3 = nn.Sequential(\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.LeakyReLU(negative_slope=0.1),\n            nn.MaxPool2d(2, 2),\n            nn.Dropout2d(0.25)\n        )\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Sequential(\n            nn.Linear(64 * 5 * 62, 128),\n            nn.BatchNorm1d(128),\n            nn.LeakyReLU(negative_slope=0.1),\n            nn.Dropout(0.5)\n        )\n        self.fc2 = nn.Sequential(\n            nn.Linear(128, n_classes)\n        )\n\n    def forward(self, x):\n        x = self.conv1(x)  # [B, 16, 20, 250]\n        x = self.conv2(x)  # [B, 32, 10, 125]\n        x = self.conv3(x)  # [B, 64, 5, 62]\n        x = self.flatten(x)  # [B, 64*5*62]\n        x = self.fc1(x)\n        x = self.fc2(x)\n        return x\n\n# ------------------------------------------------------------------------------\n# 5️⃣ Prepare for training with more regularization\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = CNN().to(device)\n\nopt = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-5)\nloss_fn = nn.CrossEntropyLoss()\nscheduler = ReduceLROnPlateau(opt, mode='max', factor=0.5, patience=5, verbose=True)\n\n# ------------------------------------------------------------------------------\n# 6️⃣ Train the network with early stopping\nepochs = 100\nbest_val_accuracy = 0\npatience = 10\npatience_counter = 0\n\nfor epoch in range(epochs):\n    model.train()\n    epoch_loss = 0\n    for X_batch, y_batch in train_loader:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n\n        opt.zero_grad()\n        preds = model(X_batch)\n        loss = loss_fn(preds, y_batch)\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n        opt.step()\n\n        epoch_loss += loss.item()\n\n    epoch_loss /= len(train_loader)\n\n    # Validation\n    model.eval()\n    correct = 0\n    total = 0\n    val_loss = 0\n    with torch.no_grad():\n        for X_val, y_val in val_loader:\n            X_val, y_val = X_val.to(device), y_val.to(device)\n            preds = model(X_val)\n            val_loss += loss_fn(preds, y_val).item()\n            predicted = preds.argmax(1)\n            total += y_val.size(0)\n            correct += (predicted == y_val).sum().item()\n\n    val_loss /= len(val_loader)\n    val_accuracy = 100 * correct / total\n    scheduler.step(val_accuracy)  # Update learning rate\n    \n    print(f'Epoch {epoch + 1}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n\n    # Early stopping\n    if val_accuracy > best_val_accuracy:\n        best_val_accuracy = val_accuracy\n        patience_counter = 0\n        torch.save(model.state_dict(), 'best_model.pth')\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(f'Early stopping at epoch {epoch + 1}')\n            break\n\nprint(\"Training finished.\")\nprint(f\"Best validation accuracy: {best_val_accuracy:.2f}%\")\n\n# Load the best model\nmodel.load_state_dict(torch.load('best_model.pth'))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-14T13:54:52.795008Z","iopub.execute_input":"2025-06-14T13:54:52.795173Z","iopub.status.idle":"2025-06-14T14:21:21.090616Z","shell.execute_reply.started":"2025-06-14T13:54:52.795157Z","shell.execute_reply":"2025-06-14T14:21:21.089816Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Train Loss: 0.9414, Val Loss: 0.6568, Val Accuracy: 82.69%\nEpoch 2, Train Loss: 0.8681, Val Loss: 0.5718, Val Accuracy: 86.54%\nEpoch 3, Train Loss: 0.7676, Val Loss: 0.6255, Val Accuracy: 71.15%\nEpoch 4, Train Loss: 0.7650, Val Loss: 0.6810, Val Accuracy: 51.92%\nEpoch 5, Train Loss: 0.7357, Val Loss: 0.9693, Val Accuracy: 15.38%\nEpoch 6, Train Loss: 0.6840, Val Loss: 0.9030, Val Accuracy: 19.23%\nEpoch 7, Train Loss: 0.6742, Val Loss: 0.7940, Val Accuracy: 28.85%\nEpoch 8, Train Loss: 0.6561, Val Loss: 0.7273, Val Accuracy: 46.15%\nEpoch 9, Train Loss: 0.5779, Val Loss: 0.7882, Val Accuracy: 38.46%\nEpoch 10, Train Loss: 0.5714, Val Loss: 0.8213, Val Accuracy: 32.69%\nEpoch 11, Train Loss: 0.5424, Val Loss: 0.9616, Val Accuracy: 23.08%\nEpoch 12, Train Loss: 0.5510, Val Loss: 0.9762, Val Accuracy: 23.08%\nEarly stopping at epoch 12\nTraining finished.\nBest validation accuracy: 86.54%\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}